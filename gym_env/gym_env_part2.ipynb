{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gymnasium Custom Environment - Create a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gymnasium packages contain a list of environments to test our Reinforcement Learning (RL) algorithm. For example, this previous notebook used FrozenLake environment to test a TD-lerning method. While these environments are greate testbeds, we often want to customize the provided environment to see how an agent behaves in different environments. It is also a great interest to create own custom environment and test our algorithm. \n",
    "gymnasium provides an easy way to do them. In this series of notebooks, we will learn\n",
    "- How to edit an existing environment in gymnasium (last nootebook)\n",
    "- How to create a custom environment with gymnasium (this notebook)\n",
    "\n",
    "In this notebook, we will create a fun environment to play Pokemon Red Game. This is motivated by [this cool work](https://www.youtube.com/watch?v=DcYLT37ImBY&t=1741s) by Peter Whidden and [another work](https://github.com/Baekalfen/PyBoy) by Asger Anders Lund Hansen, Mads Ynddal, and Troels Ynddal. The code is mainly adapted from [Peter's git repository](https://github.com/PWhiddy/PokemonRedExperiments) but simplified to convey the key points to define a custom environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 necessary functions to define a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As reviewed in the previous notebook, a gymnasium environment has four key functions listed as below (obstained from [official documentation](https://gymnasium.farama.org/api/env/))\n",
    "- reset() : Resets the environment to an initial state, required before calling step. Returns the first agent observation for an episode and information, i.e. metrics, debug info.\n",
    "\n",
    "- step() : Updates an environment with actions returning the next agent observation, the reward for taking that actions, if the environment has terminated or truncated due to the latest action and information from the environment about the step, i.e. metrics, debug info.\n",
    "\n",
    "- render() : Renders the environments to help visualise what the agent see, examples modes are “human”, “rgb_array”, “ansi” for text.\n",
    "\n",
    "- close() : Closes the environment, important when external software is used, i.e. pygame for rendering, databases\n",
    "\n",
    "When designing a custom environment, we inherit \"Env\" class of gymnasium. Then, we re-define these four functions based on our needs. Inheriting \"Env\" class is crucial because it:\n",
    "\n",
    "- provides access to a rich set of base functionalities and utilities within the Gymnasium library, such as methods for seeding randomness.\n",
    "- ensures that the custom environment adheres to the Gymnasium framework's standardized interface, allowing it to be used interchangeably with other Gym environments.\n",
    "- facilitates the integration with other Gymnasium tools and plugins, enhancing the environment's capabilities and simplifying the development and testing process.\n",
    "\n",
    "By inheriting from the Env class, we can focus on defining the unique aspects of our custom environment such as its observation space, action space, and dynamics, while leveraging the established infrastructure provided by Gymnasium for simulation control, rendering, and interaction with learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pokemon Red Game environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start defining the pokemon environment.\n",
    "\n",
    "To create a Pokemon Red Game environment, we use a python based game boy emulator called [PyBoy](https://github.com/Baekalfen/PyBoy).\n",
    "In the Pokemon Red Game environment, there are 7 commands (i.e. action) the agent can use to explore the world:\n",
    "- Press arrow up\n",
    "- Press arrow down\n",
    "- Press arrow right \n",
    "- Press arrow left\n",
    "- Press A botton\n",
    "- Press B botton\n",
    "- Press start botton\n",
    "\n",
    "These are the same commands we can use to play Pokemon Red! The state an agent can be in is defined by the game map. The observed state is a 144x160x3 grid of images (i.e. one 36x40 grid image for RGB). For reward function, we can design it as we want. For this tutorial, let's define a reward as a sum of level of all pokemons caught so far for simplicity. (Note that we need a more sophisticated reward function to train an agent to play pokemon red.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioend above, we will create our class by inheriting Env class of gymnausium. Then, we will implement four essential functions, reset, step, render, and close for our new custom class. Before defining these functions, we will first learn the implementation of initialization. This initializaiton process is invoked when the environment is first created. This process establishes the key characteristics of the environment.\n",
    "\n",
    "During initialization, we define several critical aspects:\n",
    "- Action space: A set of all possible actions that an agent can take in the environment. It's a way to outline what actions are available for the agent to choose from at any given step\n",
    "\n",
    "- Observation space: A size or shape of the observations that the agent receives from the environment. Essentially, it describes the form and structure of the data the agent uses to make decisions\n",
    "\n",
    "- Action frequency: A number of frames before a new action is taken. In the context of PyBoy, an action can be applied once every 24 frames. This setting controls the pace at which the agent can act within the game environment\n",
    "\n",
    "- Pyboy object: An object to interface with the actual game environment provided by PyBoy. It acts as the bridge between our custom gymnausium environment and the Game Boy game we aim to interact with\n",
    "\n",
    "- Initial state: A starting state of the agent when the environment is initialized. For the purpose of this tutorial, we will set the initial state to be the moment after choosing the first pokemon, as demonstrated in Peter Whidden's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyboy import PyBoy\n",
    "\n",
    "from gymnasium import Env, spaces\n",
    "from pyboy.utils import WindowEvent\n",
    "from skimage.transform import resize\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedGymEnv(Env):\n",
    "    def __init__(self, config):\n",
    "        super(RedGymEnv, self).__init__() # should I do this?\n",
    "        # Define action psace\n",
    "        self.valid_actions = [\n",
    "            WindowEvent.PRESS_ARROW_DOWN,\n",
    "            WindowEvent.PRESS_ARROW_LEFT,\n",
    "            WindowEvent.PRESS_ARROW_RIGHT,\n",
    "            WindowEvent.PRESS_ARROW_UP,\n",
    "            WindowEvent.PRESS_BUTTON_A,\n",
    "            WindowEvent.PRESS_BUTTON_B,\n",
    "        ]\n",
    "        self.action_space = spaces.Discrete(len(self.valid_actions))\n",
    "        \n",
    "        self.valid_actions.extend([\n",
    "            WindowEvent.PRESS_BUTTON_START,\n",
    "            WindowEvent.PASS\n",
    "        ])\n",
    "\n",
    "        self.release_arrow = [\n",
    "            WindowEvent.RELEASE_ARROW_DOWN,\n",
    "            WindowEvent.RELEASE_ARROW_LEFT,\n",
    "            WindowEvent.RELEASE_ARROW_RIGHT,\n",
    "            WindowEvent.RELEASE_ARROW_UP\n",
    "        ]\n",
    "\n",
    "        self.release_button = [\n",
    "            WindowEvent.RELEASE_BUTTON_A,\n",
    "            WindowEvent.RELEASE_BUTTON_B\n",
    "        ]\n",
    "        \n",
    "        # Define observation space\n",
    "        self.output_shape = (144, 160, 1)\n",
    "        self.output_full_shape = (144, 160, 3) # 3: RGB\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=self.output_full_shape, dtype=np.uint8)\n",
    "\n",
    "        # Define action frequency\n",
    "        self.act_freq = config['action_freq']\n",
    "\n",
    "        # Create pyboy object\n",
    "        head = 'SDL2'\n",
    "        self.pyboy = PyBoy(\n",
    "                config['gb_path'],\n",
    "                debugging=False,\n",
    "                disable_input=False,\n",
    "                window_type=head,\n",
    "                hide_window='--quiet' in sys.argv,\n",
    "            )\n",
    "\n",
    "        # Initialize the state\n",
    "        self.init_state = config['init_state']\n",
    "        with open(self.init_state, \"rb\") as f:\n",
    "            self.pyboy.load_state(f)  \n",
    "\n",
    "        # Initialize a generator of a game image\n",
    "        self.screen = self.pyboy.botsupport_manager().screen()\n",
    "\n",
    "        # Initailize variables to monitor agent's state and reward        \n",
    "        self.agent_stats = []\n",
    "        self.total_reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a render function. This function returns the pixel values of the game screen at any given moment. By default, the screen pixel size in PyBoy is set to (144, 160, 3), representing the resolution and color depth (RGB) of the Game Boy's display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(self):\n",
    "    game_pixels_render = self.screen.screen_ndarray() # (144, 160, 3)\n",
    "    return game_pixels_render\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a reset function. When we run multiple episodes of simulation, we call reset function at the beginning of each episode to reset the environment to a predefined initial state. Note that initialization function (__init__) is called when the environment is created only once when the environment is first created. After that, at the beginning of each new episode, reset function will be called for initialization of the environment, ensuring that each episode starts from a consistent state.\n",
    "Within this function, for our specific case, we will initialize the state and the total reward value as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self):\n",
    "    # restart game, skipping credits\n",
    "    with open(self.init_state, \"rb\") as f:\n",
    "        self.pyboy.load_state(f)  \n",
    "    \n",
    "    # reset reward value\n",
    "    self.total_reward = 0\n",
    "    return self.render(), {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a step in the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define step function. We pass an action as its argument. This function moves the agent based on the specified action and returns the new state, obtained reward, and whether the episode is terminated/truncated. For simplicity, we don't consider the termination or truncation condition in this implementaiton. Thus, the episode is terminated when we stop the execution of this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "    \n",
    "    # take an aciton\n",
    "    # press button\n",
    "    self.pyboy.send_input(self.valid_actions[action])\n",
    "    for i in range(self.act_freq):\n",
    "        # release action not to keep taking the action\n",
    "        if i == 8:\n",
    "            if action < 4:\n",
    "                # release arrow\n",
    "                self.pyboy.send_input(self.release_arrow[action])\n",
    "            if action > 3 and action < 6:\n",
    "                # release button \n",
    "                self.pyboy.send_input(self.release_button[action - 4])\n",
    "            if self.valid_actions[action] == WindowEvent.PRESS_BUTTON_START:\n",
    "                self.pyboy.send_input(WindowEvent.RELEASE_BUTTON_START)\n",
    "                \n",
    "        # render pyBoy image at the last frame of each block\n",
    "        if i == self.act_freq-1:\n",
    "            self.pyboy._rendering(True)\n",
    "        self.pyboy.tick()\n",
    "\n",
    "    # store the new agent state obtained from the corresponding memory address\n",
    "    # memory addresses from https://datacrystal.romhacking.net/wiki/Pok%C3%A9mon_Red/Blue:RAM_map\n",
    "    X_POS_ADDRESS, Y_POS_ADDRESS = 0xD362, 0xD361\n",
    "    LEVELS_ADDRESSES = [0xD18C, 0xD1B8, 0xD1E4, 0xD210, 0xD23C, 0xD268]    \n",
    "    x_pos = self.pyboy.get_memory_value(X_POS_ADDRESS)\n",
    "    y_pos = self.pyboy.get_memory_value(Y_POS_ADDRESS)\n",
    "    levels = [self.pyboy.get_memory_value(a) for a in LEVELS_ADDRESSES]\n",
    "    self.agent_stats.append({\n",
    "        'x': x_pos, 'y': y_pos, 'levels': levels\n",
    "    })\n",
    "\n",
    "    # store the new screen image (i.e. new observation) and reward    \n",
    "    obs_memory = self.render()\n",
    "    new_reward = levels\n",
    "    \n",
    "    # for simplicity, don't handle terminate or truncated conditions here\n",
    "    terminated = False # no max number of step\n",
    "    truncated = False # no max number of step\n",
    "\n",
    "    return obs_memory, new_reward, terminated, truncated, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define a close function to properly clean up any resources that were used. We will reuse the close function from the parent's class here. At the same time, we add a code to close pyBoy session. \n",
    "\n",
    "Lastly, we will define a close function to ensure proper cleanup of any resources used during the simulation. We will inherit and use the close function from the parent class. Additionally, we will include code specifically designed to terminate the PyBoy session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close(self):\n",
    "    self.pyboy.stop() # terminate pyboy session\n",
    "    super().close() # call close function of parent's class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate all functions and define a whole class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's integrate all functions, define the whole RedGymEnv class, and test our implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedGymEnv(Env):\n",
    "    def __init__(self, config):\n",
    "        super(RedGymEnv, self).__init__() # should I do this?\n",
    "        # Define action psace\n",
    "        self.valid_actions = [\n",
    "            WindowEvent.PRESS_ARROW_DOWN,\n",
    "            WindowEvent.PRESS_ARROW_LEFT,\n",
    "            WindowEvent.PRESS_ARROW_RIGHT,\n",
    "            WindowEvent.PRESS_ARROW_UP,\n",
    "            WindowEvent.PRESS_BUTTON_A,\n",
    "            WindowEvent.PRESS_BUTTON_B,\n",
    "        ]\n",
    "        self.action_space = spaces.Discrete(len(self.valid_actions))\n",
    "        \n",
    "        self.valid_actions.extend([\n",
    "            WindowEvent.PRESS_BUTTON_START,\n",
    "            WindowEvent.PASS\n",
    "        ])\n",
    "\n",
    "        self.release_arrow = [\n",
    "            WindowEvent.RELEASE_ARROW_DOWN,\n",
    "            WindowEvent.RELEASE_ARROW_LEFT,\n",
    "            WindowEvent.RELEASE_ARROW_RIGHT,\n",
    "            WindowEvent.RELEASE_ARROW_UP\n",
    "        ]\n",
    "\n",
    "        self.release_button = [\n",
    "            WindowEvent.RELEASE_BUTTON_A,\n",
    "            WindowEvent.RELEASE_BUTTON_B\n",
    "        ]\n",
    "        \n",
    "        # Define observation space\n",
    "        self.output_shape = (144, 160, 1)\n",
    "        self.output_full_shape = (144, 160, 3) # 3: RGB\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=self.output_full_shape, dtype=np.uint8)\n",
    "\n",
    "        # Define action frequency\n",
    "        self.act_freq = config['action_freq']\n",
    "\n",
    "        # Create pyboy object\n",
    "        head = 'SDL2'\n",
    "        self.pyboy = PyBoy(\n",
    "                config['gb_path'],\n",
    "                debugging=False,\n",
    "                disable_input=False,\n",
    "                window_type=head,\n",
    "                hide_window='--quiet' in sys.argv,\n",
    "            )\n",
    "\n",
    "        # Initialize the state\n",
    "        self.init_state = config['init_state']\n",
    "        with open(self.init_state, \"rb\") as f:\n",
    "            self.pyboy.load_state(f)  \n",
    "\n",
    "        # Initialize a generator of a game image\n",
    "        self.screen = self.pyboy.botsupport_manager().screen()\n",
    "\n",
    "        # Initailize variables to monitor agent's state and reward        \n",
    "        self.agent_stats = []\n",
    "        self.total_reward = 0\n",
    "        \n",
    "    def render(self):\n",
    "        game_pixels_render = self.screen.screen_ndarray() # (144, 160, 3)\n",
    "        return game_pixels_render\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # restart game, skipping credits\n",
    "        with open(self.init_state, \"rb\") as f:\n",
    "            self.pyboy.load_state(f)  \n",
    "        \n",
    "        # reset reward value\n",
    "        self.total_reward = 0\n",
    "        return self.render(), {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        # take an aciton\n",
    "        # press button\n",
    "        self.pyboy.send_input(self.valid_actions[action])\n",
    "        for i in range(self.act_freq):\n",
    "            # release action not to keep taking the action\n",
    "            if i == 8:\n",
    "                if action < 4:\n",
    "                    # release arrow\n",
    "                    self.pyboy.send_input(self.release_arrow[action])\n",
    "                if action > 3 and action < 6:\n",
    "                    # release button \n",
    "                    self.pyboy.send_input(self.release_button[action - 4])\n",
    "                if self.valid_actions[action] == WindowEvent.PRESS_BUTTON_START:\n",
    "                    self.pyboy.send_input(WindowEvent.RELEASE_BUTTON_START)\n",
    "                    \n",
    "            # render pyBoy image at the last frame of each block\n",
    "            if i == self.act_freq-1:\n",
    "                self.pyboy._rendering(True)\n",
    "            self.pyboy.tick()\n",
    "\n",
    "        # store the new agent state obtained from the corresponding memory address\n",
    "        # memory addresses from https://datacrystal.romhacking.net/wiki/Pok%C3%A9mon_Red/Blue:RAM_map\n",
    "        X_POS_ADDRESS, Y_POS_ADDRESS = 0xD362, 0xD361\n",
    "        LEVELS_ADDRESSES = [0xD18C, 0xD1B8, 0xD1E4, 0xD210, 0xD23C, 0xD268]    \n",
    "        x_pos = self.pyboy.get_memory_value(X_POS_ADDRESS)\n",
    "        y_pos = self.pyboy.get_memory_value(Y_POS_ADDRESS)\n",
    "        levels = [self.pyboy.get_memory_value(a) for a in LEVELS_ADDRESSES]\n",
    "        self.agent_stats.append({\n",
    "            'x': x_pos, 'y': y_pos, 'levels': levels\n",
    "        })\n",
    "\n",
    "        # store the new screen image (i.e. new observation) and reward    \n",
    "        obs_memory = self.render()\n",
    "        new_reward = levels\n",
    "        \n",
    "        # for simplicity, don't handle terminate or truncated conditions here\n",
    "        terminated = False # no max number of step\n",
    "        truncated = False # no max number of step\n",
    "\n",
    "        return obs_memory, new_reward, terminated, truncated, {}\n",
    "\n",
    "    def close(self):\n",
    "        self.pyboy.stop() # terminate pyboy session\n",
    "        super().close() # call close function of parent's class\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the current state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, after initializing the environment, we choose random action for 30 steps and visualize the pokemon game screen using render function.\n",
    "Since we need to use Pokemon Rom file to run this environment, we cannot run it on kaggle. Here is how you can run the below code.\n",
    "1. Download this notebook\n",
    "2. Legally obtain Pokemon Red ROM file (You can find this using google)\n",
    "3. Download has_pokedex_nballs.state file from [this github repository](https://github.com/PWhiddy/PokemonRedExperiments)\n",
    "4. Upload the below two path variables based on where each file is on your machine\n",
    "5. Uncomment below cell\n",
    "6. Ready to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROM_PATH = \"\"\n",
    "INIT_STATE_FILE_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_config = {\n",
    "#             'action_freq': 24, 'init_state': INIT_STATE_PATH,\n",
    "#             'gb_path': ROM_PATH\n",
    "#         }\n",
    "# env = RedGymEnv(env_config)\n",
    "# env.reset()\n",
    "# states = []\n",
    "# rewards = []\n",
    "\n",
    "# try:\n",
    "#     for i in range(30): # run for 30 steps\n",
    "#         random_action = np.random.choice(list(range(len(env.valid_actions))),size=1)[0]\n",
    "#         observation, reward, terminated, truncated, _ = env.step(random_action)\n",
    "#         states.append(observation)\n",
    "#         rewards.append(reward)\n",
    "\n",
    "#         # Display the current state of the environment\n",
    "#         clear_output(wait=True)\n",
    "#         plt.imshow(env.render())\n",
    "#         plt.show()\n",
    "# finally:\n",
    "#     env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up your environment, you should be able to see something like below video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"center\"><iframe align = \"middle\" width=\"790\" height=\"440\" src=\"https://www.youtube.com/embed/kX_hQjFWqs4?si=Hh5toQP2m2fczMCe\" title=\"Pokemon 30 steps\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<div align=\"center\"><iframe align = \"middle\" width=\"790\" height=\"440\" src=\"https://www.youtube.com/embed/kX_hQjFWqs4?si=Hh5toQP2m2fczMCe\" title=\"Pokemon 30 steps\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is working - RRed is now navigating the game screen in response to the action commands. With gymnasium, we've successfully created a custom environment for training RL agents.\n",
    "\n",
    "In future notebooks, I plan to use this environment for training RL agents. Stay tuned for updates and progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PokemonRedExperiments github repository by Peter Whidden (https://github.com/PWhiddy/PokemonRedExperiments)\n",
    "- PyBoy github repository (https://github.com/Baekalfen/PyBoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokemon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
